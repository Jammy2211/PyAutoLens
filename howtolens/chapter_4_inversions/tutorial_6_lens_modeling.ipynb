{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 6: Lens Modeling\n",
        "=========================\n",
        "\n",
        "When modeling complex source's with parametric profiles, we quickly entered a regime where our `NonLinearSearch` was\n",
        "faced with a parameter space of dimensionality N=30+ parameters. This made the model-fitting inefficient, and very\n",
        "likely to infer a local maxima.\n",
        "\n",
        "Because `Inversion`'s are linear, they don't suffer this problelm, making them a very a powerful tool for modeling\n",
        "strong lenses. Furthermore, they have *more* freemdom than paramwtric profiles, not relying on specific analytic\n",
        "light distributions and symmetric profile shapes, allowing us to fit more complex mass models and ask ever more\n",
        "interesting scientific questions!\n",
        "\n",
        "However, `Inversion` have some short comings that we need to be aware of before we begin using them for lens modeling.\n",
        "That`s what we are going to cover in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens `Galaxy`'s light is omitted.\n",
        " - The lens `Galaxy`'s total mass distribution is an `EllipticalIsothermal`.\n",
        " - The source `Galaxy`'s `LightProfile` is an `EllipticalSersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sie__source_sersic__2\"\n",
        "dataset_path = path.join(\"dataset\", \"howtolens\", \"chapter_4\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.05,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_2d=imaging.shape_2d, pixel_scales=imaging.pixel_scales, sub_size=2, radius=2.5\n",
        ")\n",
        "\n",
        "imaging_plotter = aplt.ImagingPlotter(\n",
        "    imaging=imaging, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "imaging_plotter.subplot_imaging()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function fits the `Imaging` data with a `Tracer`, returning a `FitImaging` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def perform_fit_with_lens__source_galaxy(imaging, lens_galaxy, source_galaxy):\n",
        "\n",
        "    mask = al.Mask2D.circular_annular(\n",
        "        shape_2d=imaging.shape_2d,\n",
        "        pixel_scales=imaging.pixel_scales,\n",
        "        sub_size=1,\n",
        "        inner_radius=0.5,\n",
        "        outer_radius=2.2,\n",
        "    )\n",
        "\n",
        "    masked_imaging = al.MaskedImaging(\n",
        "        imaging=imaging, mask=mask, settings=al.SettingsMaskedImaging(sub_size=1)\n",
        "    )\n",
        "\n",
        "    tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    return al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see the short-comings of an `Inversion`, we begin by performing a fit where the lens galaxy has an incorrect \n",
        "mass-model (I've reduced its Einstein Radius from 1.6 to 0.8). This is the sort of mass moddel the non-linear search\n",
        "might sample at the beginning of a model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.EllipticalIsothermal(\n",
        "        centre=(0.0, 0.0), elliptical_comps=(0.1, 0.0), einstein_radius=0.8\n",
        "    ),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.Rectangular(shape=(20, 20)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "fit = perform_fit_with_lens__source_galaxy(\n",
        "    imaging=imaging, lens_galaxy=lens_galaxy, source_galaxy=source_galaxy\n",
        ")\n",
        "\n",
        "include_2d = aplt.Include2D(mask=True)\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_fit_imaging()\n",
        "fit_imaging_plotter.subplot_of_planes(plane_index=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What happened!? This incorrect mass-model provides a really good_fit to the image! The residuals and chi-squared-map \n",
        "are as good as the ones we saw in the last tutorial.\n",
        "\n",
        "How can an incorrect lens model provide such a fit? Well, as I'm sure you noticed, the source has been reconstructed \n",
        "as a demagnified version of the image. Clearly, this isn't a physical solution or a solution that we want our \n",
        "non-linear search to find, but for `Inversion`'s these solutions are real; they exist.\n",
        "\n",
        "This isn't necessarily problematic for lens modeling. Afterall, the source reconstruction above is extremely complex, \n",
        "in that it requires a lot of pixels to fit the image accurately. Indeed, its Bayesian log evidence is much lower than \n",
        "the correct solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.EllipticalIsothermal(\n",
        "        centre=(0.0, 0.0), elliptical_comps=(0.1, 0.0), einstein_radius=1.6\n",
        "    ),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.Rectangular(shape=(20, 20)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "correct_fit = perform_fit_with_lens__source_galaxy(\n",
        "    imaging=imaging, lens_galaxy=lens_galaxy, source_galaxy=source_galaxy\n",
        ")\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=correct_fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_fit_imaging()\n",
        "fit_imaging_plotter.subplot_of_planes(plane_index=1)\n",
        "\n",
        "print(\"Bayesian Evidence of Incorrect Fit:\")\n",
        "print(fit.log_evidence)\n",
        "print(\"Bayesian Evidence of Correct Fit:\")\n",
        "print(correct_fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The log evidence *is* lower. However, the difference in log evidence isn't *that large*. This is going to be a problem \n",
        "for the non-linear search, as its going to see *a lot* of solutions with really high log evidence value. Furthermore, \n",
        "these solutions occupy a *large volumne* of parameter space (e.g. everywhere the lens model that is wrong). This makes \n",
        "it easy for the `NonLinearSearch` to get lost searching through these unphysical solutions and, unfortunately, infer an \n",
        "incorrect lens model (e.g. a local maxima).\n",
        "\n",
        "There is no simple fix for this. The reality is that for an `Inversion` these solutions exist. This is how phase \n",
        "linking and pipelines were initially conceived, they offer a simple solution to this problem. We write a pipeline that \n",
        "begins by modeling the source galaxy as a `LightProfile`, `initializing` our lens mass model. Then, when we switch to \n",
        "an `Inversion` in the next phase, our mass model starts in the correct regions of parameter space and doesn`t get lost \n",
        "sampling these incorrect solutions.\n",
        "\n",
        "Its not ideal, but its also not a big problem. Furthermore, `LightProfile`'ss run faster computationally than \n",
        "`Inversion`'s, so breaking down the lens modeling procedure in this way is actually a lot faster than starting with an\n",
        "`Inversion` anyway!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, so we've covered incorrect solutions, lets end by noting that we can model profiles and inversions at the same \n",
        "time. We do this when we want to simultaneously fit and subtract the light of a lens galaxy and reconstruct its lensed \n",
        "source using an `Inversion`. To do this, all we have to do is give the lens galaxy a `LightProfile`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"light_sersic__mass_sie__source_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"howtolens\", \"chapter_4\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.05,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_2d=imaging.shape_2d, pixel_scales=imaging.pixel_scales, sub_size=2, radius=2.5\n",
        ")\n",
        "\n",
        "imaging_plotter = aplt.ImagingPlotter(\n",
        "    imaging=imaging, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "imaging_plotter.subplot_imaging()\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_of_planes(plane_index=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When fitting such an image we now want to include the lens`s light in the analysis. Lets update our mask to be \n",
        "circular so that it includes the central regions of the image and lens galaxy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_2d=imaging.shape_2d, pixel_scales=imaging.pixel_scales, sub_size=2, radius=2.5\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As I said above, performing this fit is the same as usual, we just give the lens galaxy a `LightProfile`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=al.lp.SphericalSersic(\n",
        "        centre=(0.0, 0.0), intensity=0.2, effective_radius=0.8, sersic_index=4.0\n",
        "    ),\n",
        "    mass=al.mp.EllipticalIsothermal(\n",
        "        centre=(0.0, 0.0), elliptical_comps=(0.1, 0.0), einstein_radius=1.6\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are all the usual things we do when setting up a fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.Rectangular(shape=(20, 20)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "masked_imaging = al.MaskedImaging(\n",
        "    imaging=imaging, mask=mask, settings=al.SettingsMaskedImaging(sub_size=2)\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This fit now subtracts the lens `Galaxy`'s light from the image and fits the resulting source-only image with the \n",
        "`Inversion`. When we plot the image, a new panel on the sub-plot appears showing the model image of the lens galaxy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n",
        "\n",
        "include_2d = aplt.Include2D(mask=True)\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_fit_imaging()\n",
        "fit_imaging_plotter.subplot_of_planes(plane_index=1)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course if the lens subtraction is rubbish so is our fit, so we can be sure that our lens model wants to fit the \n",
        "lens `Galaxy`'s light accurately (below, I've increased the lens galaxy intensity from 0.2 to 0.3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=al.lp.SphericalSersic(\n",
        "        centre=(0.0, 0.0), intensity=0.3, effective_radius=0.8, sersic_index=4.0\n",
        "    ),\n",
        "    mass=al.mp.EllipticalIsothermal(\n",
        "        centre=(0.0, 0.0), elliptical_comps=(0.1, 0.0), einstein_radius=1.6\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "fit = al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n",
        "\n",
        "include_2d = aplt.Include2D(mask=True)\n",
        "\n",
        "fit_imaging_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include_2d)\n",
        "fit_imaging_plotter.subplot_fit_imaging()\n",
        "fit_imaging_plotter.subplot_of_planes(plane_index=1)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And with that, we're done. Finally, I'll point out a few things about what we've covered to get you thinking about \n",
        "the next tutorial on adaption.\n",
        "\n",
        " - The unphysical solutions above are clearly problematic. Whilst they have lower Bayesian evidences their existance \n",
        " will still impact our inferred lens model. However, the `Pixelization`'s that we used in this chapter do not \n",
        " adapt to the images they are fitting, meaning the correct solutions achieve much lower Bayesian log evidence \n",
        " values than is actually possible. Thus, once we've covered adaption, these issues will be resolved!\n",
        "    \n",
        " - When the lens `Galaxy`'s light is subtracted perfectly it leaves no residuals. However, if it isn't subtracted \n",
        " perfectly it does leave residuals, which will be fitted by the `Inversion`. If the residual are significant this is \n",
        " going to mess with our source reconstruction and can lead to some pretty nasty systematics. In the next chapter, \n",
        " we'll learn how our adaptive analysis can prevent this residual fitting."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}